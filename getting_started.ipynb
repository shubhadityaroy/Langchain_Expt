{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\shubh\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - langchain\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    async-timeout-4.0.3        |     pyhd8ed1ab_0          11 KB  conda-forge\n",
      "    certifi-2024.2.2           |     pyhd8ed1ab_0         157 KB  conda-forge\n",
      "    chardet-5.2.0              |  py311h1ea47a8_1         278 KB  conda-forge\n",
      "    dataclasses-json-0.6.4     |     pyhd8ed1ab_0          29 KB  conda-forge\n",
      "    jsonpatch-1.33             |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    langchain-0.1.9            |     pyhd8ed1ab_0         425 KB  conda-forge\n",
      "    langchain-community-0.0.32 |     pyhd8ed1ab_0         905 KB  conda-forge\n",
      "    langchain-core-0.1.42      |     pyhd8ed1ab_0         186 KB  conda-forge\n",
      "    langsmith-0.1.47           |     pyhd8ed1ab_0          90 KB  conda-forge\n",
      "    marshmallow-3.21.1         |     pyhd8ed1ab_0          90 KB  conda-forge\n",
      "    openssl-3.2.1              |       hcfcfb64_1         7.8 MB  conda-forge\n",
      "    orjson-3.9.15              |  py311h633b200_0         185 KB  conda-forge\n",
      "    packaging-23.2             |     pyhd8ed1ab_0          48 KB  conda-forge\n",
      "    python_abi-3.11            |          2_cp311           5 KB  conda-forge\n",
      "    typing_inspect-0.9.0       |     pyhd8ed1ab_0          15 KB  conda-forge\n",
      "    ucrt-10.0.22621.0          |       h57928b3_0         1.2 MB  conda-forge\n",
      "    vc14_runtime-14.38.33130   |      h82b7239_18         732 KB  conda-forge\n",
      "    vs2015_runtime-14.38.33130 |      hcb4865c_18          17 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        12.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  async-timeout      conda-forge/noarch::async-timeout-4.0.3-pyhd8ed1ab_0 \n",
      "  dataclasses-json   conda-forge/noarch::dataclasses-json-0.6.4-pyhd8ed1ab_0 \n",
      "  langchain          conda-forge/noarch::langchain-0.1.9-pyhd8ed1ab_0 \n",
      "  langchain-communi~ conda-forge/noarch::langchain-community-0.0.32-pyhd8ed1ab_0 \n",
      "  langchain-core     conda-forge/noarch::langchain-core-0.1.42-pyhd8ed1ab_0 \n",
      "  langsmith          conda-forge/noarch::langsmith-0.1.47-pyhd8ed1ab_0 \n",
      "  marshmallow        conda-forge/noarch::marshmallow-3.21.1-pyhd8ed1ab_0 \n",
      "  orjson             conda-forge/win-64::orjson-3.9.15-py311h633b200_0 \n",
      "  python_abi         conda-forge/win-64::python_abi-3.11-2_cp311 \n",
      "  typing_inspect     conda-forge/noarch::typing_inspect-0.9.0-pyhd8ed1ab_0 \n",
      "  ucrt               conda-forge/win-64::ucrt-10.0.22621.0-h57928b3_0 \n",
      "  vc14_runtime       conda-forge/win-64::vc14_runtime-14.38.33130-h82b7239_18 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  chardet            pkgs/main::chardet-4.0.0-py311haa9553~ --> conda-forge::chardet-5.2.0-py311h1ea47a8_1 \n",
      "  jsonpatch          pkgs/main::jsonpatch-1.32-pyhd3eb1b0_0 --> conda-forge::jsonpatch-1.33-pyhd8ed1ab_0 \n",
      "  openssl              pkgs/main::openssl-3.0.13-h2bbff1b_0 --> conda-forge::openssl-3.2.1-hcfcfb64_1 \n",
      "  packaging          pkgs/main/win-64::packaging-23.1-py31~ --> conda-forge/noarch::packaging-23.2-pyhd8ed1ab_0 \n",
      "  vs2015_runtime     pkgs/main::vs2015_runtime-14.27.29016~ --> conda-forge::vs2015_runtime-14.38.33130-hcb4865c_18 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/win-64::certifi-2024.2.2-py~ --> conda-forge/noarch::certifi-2024.2.2-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLangsmith is a tool that can help with testing in several ways:\\n\\n1. Automated Testing: Langsmith provides a framework for automating tests, allowing developers to write and run tests more efficiently.\\n2. Code Coverage Analysis: Langsmith can analyze the coverage of your tests, providing insights into which parts of your code are covered by your tests and which areas need more attention.\\n3. Test Case Generation: Langsmith can generate test cases based on your existing tests, helping to identify gaps in your testing coverage and reduce the time spent writing new tests.\\n4. Test Runner: Langsmith provides a test runner that allows you to run your tests quickly and efficiently, providing detailed feedback on test results.\\n5. Integration with CI/CD Pipelines: Langsmith can be integrated with your continuous integration (CI) and continuous deployment (CD) pipelines, allowing you to automate testing and deployment processes.\\n6. Test Data Management: Langsmith provides tools for managing test data, including data generators and data providers, which can help ensure that your tests are running with accurate and relevant data.\\n7. Integration with Popular Programming Languages: Langsmith supports popular programming languages such as Java, Python, Ruby, and PHP, making it easy to integrate into your development workflow.\\n8. Customizable Testing Framework: Langsmith allows you to define your own testing framework, allowing you to tailor the tool to your specific testing needs.\\n9. Support for Different Testing Methodologies: Langsmith supports different testing methodologies such as unit testing, integration testing, and acceptance testing, making it easy to adopt a consistent testing approach across your organization.\\n10. Scalability: Langsmith is designed to scale with your testing needs, providing the necessary features and functionality for large-scale testing projects.\\n\\nOverall, Langsmith can help streamline and simplify the testing process, reducing the time and effort required to write, run, and maintain tests. This can help improve the overall quality of your software and reduce the risk of bugs and errors.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAs a world-class technical documentation writer, I must say that LingSMITH is an excellent tool for testing and quality assurance in the field of technical writing. Here are some ways Langsmith can help with testing:\\n\\n1. Grammar and Spell Checking: Langsmith's advanced grammar and spell checking capabilities can help identify and fix errors in your technical documents that might have been missed by a human proofreader.\\n2. Consistency Checking: Langsmith can check for consistency in formatting, style, and terminology throughout your technical documents, ensuring that they are consistent and easy to read.\\n3. Concept Mapping: Langsmith's concept mapping feature can help you create clear and organized diagrams and flowcharts to illustrate complex concepts and ideas in your technical documents.\\n4. Content Analysis: Langsmith's content analysis capabilities can help you identify key themes, topics, and trends in large volumes of technical data, enabling you to create more targeted and effective documentation.\\n5. Style Guidance: Langsmith can provide style guidance based on industry-specific guidelines, such as APA, MLA, or Chicago, ensuring that your technical documents are written in the correct style and format.\\n6. Redundancy Detection: Langsmith's redundancy detection capabilities can help identify and eliminate redundant language and content in your technical documents, improving their overall readability and effectiveness.\\n7. Contextualized Writing: Langsmith's contextualized writing capabilities can help you create more accurate and relevant technical documentation by analyzing the context of the content being written.\\n8. Collaboration Tools: Langsmith's collaboration tools allow multiple users to work together on a project, streamlining the testing and review process for technical documents.\\n9. Integration with Other Tools: Langsmith can integrate with other tools and platforms, such as version control systems, project management software, and documentation management systems, enabling seamless collaboration and workflow management.\\n10. Customization: Langsmith can be customized to fit the specific needs of your organization, allowing you to tailor the tool to your unique technical writing processes and requirements.\\n\\nIn summary, Langsmith is an indispensable tool for technical documentation writers, providing a range of features that can help improve the accuracy, consistency, and readability of technical documents. By leveraging these capabilities, you can streamline your testing and quality assurance process, ensuring that your technical documents are of the highest quality and meet the needs of your audience.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAs a world-class technical documentation writer, I must say that Langsmith is an excellent tool for testing and ensuring the quality of your technical content. Here are some ways in which Langsmith can help with testing:\\n\\n1. Grammar and Spell Checking: Langsmith has a built-in grammar and spell checker that can identify and correct errors in your text. This can save you a significant amount of time and effort, as you don't have to manually proofread your content.\\n2. Contextualization: Langsmith's AI-powered contextualizer can help you identify potential issues with the tone, style, and format of your content. For example, it can suggest alternative phrases or sentences that are more appropriate for a particular context or audience.\\n3. Consistency Checking: Langsmith can check your content for consistency in terms of formatting, styling, and terminology. This can help ensure that your documentation is consistent throughout, which can improve readability and usability.\\n4. Error Detection: Langsmith's AI-powered error detection can identify a wide range of errors, including grammatical errors, spelling mistakes, and inconsistencies in formatting and styling. This can save you time and effort when it comes to reviewing and editing your content.\\n5. Collaboration: Langsmith allows multiple users to collaborate on technical documentation projects. This can help ensure that everyone is on the same page and working towards a common goal, which can improve the overall quality of your documentation.\\n6. Customization: Langsmith offers a range of customization options, including the ability to create custom templates, styles, and formats. This can help you create technical documentation that is tailored to your specific needs and requirements.\\n7. Integration with other tools: Langsmith can integrate with other tools such as JIRA, Confluence, and GitHub, which can help streamline your development process and improve the overall quality of your technical documentation.\\n\\nIn summary, Langsmith can help you test and ensure the quality of your technical content by providing advanced grammar and spell checking, contextualization, consistency checking, error detection, collaboration, customization, and integration with other tools.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.5 MB 907.3 kB/s eta 0:00:16\n",
      "    --------------------------------------- 0.3/14.5 MB 2.0 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/14.5 MB 3.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.9/14.5 MB 4.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.2/14.5 MB 4.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 5.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 5.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.4/14.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.7/14.5 MB 5.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.0/14.5 MB 5.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.3/14.5 MB 5.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.8/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.1/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.4/14.5 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/14.5 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.2/14.5 MB 5.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.4/14.5 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.4/14.5 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.7/14.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.6/14.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.9/14.5 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.3/14.5 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.6/14.5 MB 5.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.3/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.6/14.5 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.9/14.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.2/14.5 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.5/14.5 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.8/14.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.0/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.3/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.6/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.9/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.2/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 6.1 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_text_splitters\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain_text_splitters) (0.1.42)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (0.1.47)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (8.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (3.9.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2024.2.2)\n",
      "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: langchain_text_splitters\n",
      "Successfully installed langchain_text_splitters-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the provided context, langsmith can help with testing by allowing users to visualize their test results. This means that langsmith can provide a visual representation of the test data, making it easier for users to understand and analyze the results. This can be particularly useful in situations where large amounts of data are generated during testing, as it allows users to quickly identify patterns or trends in the data without having to manually review each result.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the provided context, LangSmith can help with testing in several ways:\n",
      "\n",
      "1. Prototyping: LangSmith supports rapid experimentation between prompts, model types, and retrieval strategies, making it easier to understand how the model performs and debug where it fails.\n",
      "2. Initial Test Set: LangSmith allows developers to create datasets of inputs and reference outputs, which can be used to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\n",
      "3. Comparison View: LangSmith provides a user-friendly comparison view for test runs, allowing developers to track and diagnose regressions in test scores across multiple revisions of their application.\n",
      "4. Playground Environment: LangSmith offers a playground environment for rapid iteration and experimentation, enabling developers to quickly test out different prompts and models without having to set up a full application.\n",
      "\n",
      "Overall, LangSmith provides a range of tools and features to help developers test their LLM applications effectively.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing‚ÄãBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it‚Äôs important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it‚Äôs breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback‚ÄãWhen launching your application to an initial set of users, it‚Äôs important to gather human feedback on the responses it‚Äôs producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces‚ÄãLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset‚ÄãAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production‚ÄãClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you‚Äôll also want to do once your app hits production.However, especially at the production stage, it‚Äôs crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing‚ÄãLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period ‚Äî this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations‚ÄãAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads‚ÄãMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.Prototyping‚ÄãPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing ‚Äî and debug where it is failing ‚Äî is incredibly important for this phase.Debugging‚ÄãWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set‚ÄãWhile many developers still ship an initial version of their application based on ‚Äúvibe checks‚Äù, we‚Äôve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View‚ÄãWhen prototyping different versions of your applications and making changes, it‚Äôs important to see whether or not you‚Äôve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it‚Äôs useful to be able to view results for different configurations on the same datapoints side-by-side. We‚Äôve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground‚ÄãLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing‚ÄãBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it‚Äôs important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it‚Äôs breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback‚ÄãWhen launching your application to an initial set of users, it‚Äôs important to gather human feedback on the responses it‚Äôs producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces‚ÄãLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset‚ÄãAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production‚ÄãClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you‚Äôll also want to do once your app hits production.However, especially at the production stage, it‚Äôs crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing‚ÄãLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period ‚Äî this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations‚ÄãAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads‚ÄãMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.Prototyping‚ÄãPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing ‚Äî and debug where it is failing ‚Äî is incredibly important for this phase.Debugging‚ÄãWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set‚ÄãWhile many developers still ship an initial version of their application based on ‚Äúvibe checks‚Äù, we‚Äôve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View‚ÄãWhen prototyping different versions of your applications and making changes, it‚Äôs important to see whether or not you‚Äôve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it‚Äôs useful to be able to view results for different configurations on the same datapoints side-by-side. We‚Äôve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground‚ÄãLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'})],\n",
       " 'answer': \"Of course! LangSmith is designed to help you test and evaluate your LLM applications throughout their development lifecycle. Here are some ways LangSmith can support testing:\\n\\n1. Initial Test Set: LangSmith allows you to create datasets, which are collections of inputs and reference outputs, and use these to run tests on your LLM applications. You can upload these test cases in bulk, create them on the fly, or export them from application traces.\\n2. Comparison View: Once you've created multiple versions of your application, it's important to compare their performance side-by-side. LangSmith provides a user-friendly comparison view for test runs, allowing you to track and diagnose regressions in test scores across multiple revisions of your application.\\n3. Playground Environment: LangSmith offers a playground environment for rapid iteration and experimentation. This allows you to quickly test out different prompts and models without having to set up a separate testing environment. You can open the playground from any prompt or model run in your trace.\\n4. Beta Testing: LangSmith supports beta testing, which involves collecting more data on how your LLM application is performing in real-world scenarios. This phase is critical for developing an understanding of the types of inputs that are causing problems and how to improve the application's performance.\\n5. Annotating Traces: LangSmith also allows you to annotate traces, which involves closely inspecting key parts of your LLM application's output. You can highlight important elements, add context, and collaborate with others to better understand how your application is performing.\\n6. Production Monitoring & Automations: Once your LLM application is live, LangSmith can help you monitor its performance in production and automate tasks to keep it running smoothly. This includes monitoring token usage, response times, and other key metrics, as well as automating routine maintenance tasks like updating models or adding new features.\\n\\nBy leveraging these testing workflows, you can ensure that your LLM application is performing optimally and meeting user expectations throughout its lifecycle.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
